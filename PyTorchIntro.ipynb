{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:13.982074Z",
     "start_time": "2018-09-29T22:47:13.672095Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T14:15:27.656820Z",
     "start_time": "2018-09-25T14:15:27.652947Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  First steps with\n",
    "<img src=\"https://pytorch.org/docs/stable/_static/pytorch-logo-dark.svg\" width=800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is PyTorch ?\n",
    "It’s a Python-based scientific computing package targeted at two sets of audiences:\n",
    "\n",
    "- A replacement for NumPy to use the power of GPUs\n",
    "- a deep learning research platform that provides maximum flexibility and speed\n",
    "\n",
    "\n",
    "### PyTorch is deeply integrated into Python\n",
    "- imperative programming: access and print variables anytime (those who tried tensorflow, keras, etc will appreciate :) )\n",
    "- use python's usual debuging tools (same here :) )\n",
    "- easily integrate with numpy, scipy, pandas, sklearn, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensors and NumPy arrays\n",
    "- Tensors $\\sim$ numpy N-dimensinal arrays\n",
    "  - Can be 0-dimensional (scalars)\n",
    "  - Support for sparse tensors included\n",
    "  - intentionally similar API: same function names and indexing, slicing and broadcasting conventions\n",
    "- Tensors are loadable on GPU\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://github.com/pytorch/pytorch/raw/master/docs/source/_static/img/tensor_illustration.png\"\n",
    "         width=800/>\n",
    "    Source: https://github.com/pytorch/pytorch\n",
    "</center>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**On Numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:13.989168Z",
     "start_time": "2018-09-29T22:47:13.983435Z"
    },
    "nbpresent": {
     "id": "141f168d-2fa7-42a1-8d27-f84beb8a8300"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4], dtype=int32), array([0, 2, 4, 6, 8], dtype=int32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(5, dtype=np.int32)\n",
    "b = 2*a   \n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**On torch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:14.202070Z",
     "start_time": "2018-09-29T22:47:13.990957Z"
    },
    "nbpresent": {
     "id": "7d6fa3f5-6e33-4cdb-8c14-7a44c4d59ee0"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
       " tensor([0, 2, 4, 6, 8], dtype=torch.int32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.arange(5, dtype=torch.int32)\n",
    "b = 2*a  \n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**In-place operations**\n",
    "All in-place operators available as methods on tensor with `_` ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)  # in-place methods return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sub_(1).mul_(2) # so we can chain them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eq_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "a = torch.arange(5, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Easy conversion between frameworks\n",
    "- shared memeory between numpy arrays and cpu tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:14.207213Z",
     "start_time": "2018-09-29T22:47:14.203518Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  tensor([1, 2, 3, 4, 5], dtype=torch.int32) \n",
      "numpy:  [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "a_numpy = a.numpy()\n",
    "a_numpy += 1  # torch tensor a will also be modified\n",
    "print(\"torch: \", a, \n",
    "      \"\\nnumpy: \",a_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* create tensor from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:14.212016Z",
     "start_time": "2018-09-29T22:47:14.208574Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  tensor([2, 3, 4, 5, 6], dtype=torch.int32) \n",
      "numpy:  [2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "a_numpy2tensor = torch.from_numpy(a_numpy)\n",
    "a_numpy2tensor += 1  # numpy array will also be modified\n",
    "print(\"torch: \", a_numpy2tensor, \n",
    "      \"\\nnumpy: \",a_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An operation on GPU\n",
    "First let's time it on cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:23.179568Z",
     "start_time": "2018-09-29T22:47:14.213369Z"
    },
    "run_control": {
     "marked": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882 µs ± 162 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "a = np.random.rand(N,N).astype(np.float32)\n",
    "x = np.arange(N, dtype=np.float32)\n",
    "%timeit y = a*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:23.179568Z",
     "start_time": "2018-09-29T22:47:14.213369Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809 µs ± 60.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "a = torch.rand(N,N, dtype=torch.float32)\n",
    "x = torch.arange(N, dtype=torch.float32)\n",
    "%timeit y = a*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we do the same on gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:36.093527Z",
     "start_time": "2018-09-29T22:47:23.181024Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 µs ± 2.67 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(N,N, dtype=torch.float32, device=\"cuda\")\n",
    "x = torch.arange(N, dtype=torch.float32, device=\"cuda\")\n",
    "%timeit y = a*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pytorch binaries already include CUDA, CuDNN, NCCL, MKL, etc. - but you need to have Nvidia driver installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Attention: from cuda to numpy**\n",
    "1. bring tensor to cpu with `.cpu()`\n",
    "2. then call `.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T23:00:43.637516Z",
     "start_time": "2018-09-29T23:00:43.623270Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "y = a*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T23:00:43.637516Z",
     "start_time": "2018-09-29T23:00:43.623270Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c7fe7d326412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "#y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T22:47:40.677528Z",
     "start_time": "2018-09-29T22:47:40.663160Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 8.47667038e-01, 9.70036864e-01, ...,\n",
       "        5.83619751e+02, 8.89175903e+02, 1.15892044e+02],\n",
       "       [0.00000000e+00, 2.76412398e-01, 1.22722471e+00, ...,\n",
       "        1.75498138e+02, 8.78239014e+02, 9.45720337e+02],\n",
       "       [0.00000000e+00, 3.22977006e-01, 1.98101211e+00, ...,\n",
       "        1.48793655e+02, 6.27703613e+02, 2.54500229e+02],\n",
       "       ...,\n",
       "       [0.00000000e+00, 4.28057730e-01, 9.21844661e-01, ...,\n",
       "        8.97595825e+02, 5.86440918e+02, 9.10931885e+02],\n",
       "       [0.00000000e+00, 9.28996563e-01, 1.85661256e+00, ...,\n",
       "        8.38728088e+02, 6.05917786e+02, 6.31650757e+02],\n",
       "       [0.00000000e+00, 1.14527941e-01, 1.42226708e+00, ...,\n",
       "        1.75077759e+02, 3.80753593e+01, 3.76903900e+02]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "rise": {
   "theme": "simple",
   "transition": "none"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "327.009px",
    "width": "355.999px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.997px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.085px",
    "left": "1310.04px",
    "right": "20px",
    "top": "161.992px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
